---
description: 'Webscraper-Tool fÃ¼r Content-Extraktion und -Analyse in Evolution Hub'
owner: 'Tools Team'
priority: 'medium'
lastSync: '2025-11-26'
codeRefs: 'src/config/webscraper, src/pages/api/webscraper'
testRefs: 'tests/unit/webscraper, test-suite-v2/src/e2e/tools'
---

<!-- markdownlint-disable MD051 -->

# Webscraper Tool

**Scope** â€” Diese Kategorie dokumentiert das Webscraper-Tool fÃ¼r Content-Extraktion und -Analyse in Evolution Hub. Umfasst API-Endpunkte, Konfiguration und Nutzungsrichtlinien. Zielgruppe sind Entwickler und Power-User. Nicht enthalten: Frontend-UI (â†’ Frontend-Kategorie) oder allgemeine Scraping-Tools (â†’ externe Dokumentation).

## PrimÃ¤rdokumente

- **[Specification](./spec.md)** â€” Technische Beschreibung der aktuellen Funktionen

- **[Implementation Complete](./IMPLEMENTATION_COMPLETE.md)** â€” MVP-Status, Deploy-Anleitung und Betriebsnotizen

- **[Guidelines](./guidelines.md)** â€” Entwicklungsrichtlinien und Code-Konventionen

- **[Testing Strategy](./testing.md)** â€” Test-Pyramide, Quality-Metriken und AusfÃ¼hrungshinweise

- **[Roadmap](./roadmap.md)** â€” Geplante Erweiterungen und Phasen

## SekundÃ¤r-/Spezialdokumente

- Weitere Spezialisierungen werden aktuell direkt in den PrimÃ¤rdokumenten gepflegt. EigenstÃ¤ndige Teilkapitel fÃ¼r Usage, Rate-Limiting oder Security sind noch nicht verÃ¶ffentlicht.

## Hauptfeatures

### Content-Extraktion

- **Strukturierte Daten:** JSON/XML/HTML-Parsing

- **Smart Extraction:** KI-gestÃ¼tzte Inhaltserkennung

- **Multi-Format:** Verschiedene Output-Formate (JSON, CSV, XML)

### API-Endpunkte

- **POST /api/webscraper/extract** â€” Haupt-Extraktions-Endpunkt

- **GET /api/webscraper/usage** â€” Nutzungsstatistiken

- **GET /api/webscraper/jobs/{id}** â€” Job-Status und Ergebnisse

## Dokumentation

### Setup & Konfiguration

Setup-Hinweise werden derzeit im Abschnitt *Deployment & Betrieb* von [Implementation Complete](./IMPLEMENTATION_COMPLETE.md) dokumentiert. ErgÃ¤nzende Kapitel zu AbhÃ¤ngigkeiten oder Authentifizierung folgen mit dem nÃ¤chsten Release.

### Integration

- **Testing:** Siehe [Testing Strategy](./testing.md) fÃ¼r Unit-, Integration- und E2E-Flows

## Cross-Referenzen

- **[API Documentation](../../api/README.md)** â€” Allgemeine API-Standards und Middleware

- **[Security Documentation](../../security/README.md)** â€” Security-Richtlinien

- **[Development Documentation](../../development/README.md)** â€” Tool-Entwicklung und Testing

## Ownership & Maintenance

**Owner:** Tools Team (Lead: Tool Developer)
**Update-Frequenz:** Bei Feature-Ã„nderungen oder API-Updates
**Review-Prozess:** Code-Review + Security-Check
**Eskalation:** Bei Scraping-Problemen â†’ Backend Team

## Standards & Konventionen

- **Rate-Limiting:** 10/min fÃ¼r Standard-User, hÃ¶her fÃ¼r Enterprise

- **Output-Format:** Strukturiert und validiert

- **Security:** SSRF-Schutz, Rate-Limiting, Input-Validierung

- **Monitoring:** Nutzungsmetriken und Error-Tracking

- **Testing:** Unit-Tests fÃ¼r Parser, Integration-Tests fÃ¼r API

## Bekannte LÃ¼cken

- TODO: VollstÃ¤ndige Frontend-UI-Dokumentation

- TODO: Advanced Scraping-Features (JavaScript-Rendering)

- TODO: Enterprise-Feature-Dokumentation

## Ãœbersicht

Automatische Web-Content-Extraktion mit robots.txt Compliance

---

## ğŸ¯ Ãœberblick

Das Webscraper-Tool ermÃ¶glicht es Nutzern, strukturierte Inhalte von Webseiten automatisch zu extrahieren. Es respektiert robots.txt-Regeln, implementiert Quota-Limits und bietet eine benutzerfreundliche UI.

### Hauptfeatures (2)

- âœ… **URL-basierte Extraktion**: Titel, Meta-Daten, Text, Links, Bilder

- âœ… **robots.txt Compliance**: Automatische PrÃ¼fung und Einhaltung

- âœ… **Quota-System**: 5 Requests/Tag (Gast), 20+ Requests/Tag (User â€“ je nach Plan/Entitlements)

- âœ… **Sicherheit**: Rate-Limiting, CSRF-Schutz, Input-Validierung

- âœ… **Internationalisierung**: Deutsch/Englisch

- âœ… **Responsive UI**: Mobile-First Design mit Tailwind CSS

---

## ğŸ“‹ Dokumentation

- **[Specification](spec.md)** - Detaillierte Feature-Spezifikation

- **[Roadmap](roadmap.md)** - 14-Wochen Entwicklungsplan (Phasen 1-4)

- **[Guidelines](guidelines.md)** - Entwicklungsrichtlinien fÃ¼r Claude Code

- **[Testing Strategy](testing.md)** - Test-Pyramide und Quality-Metriken

- **[Implementation Complete](IMPLEMENTATION_COMPLETE.md)** - MVP-Status & Deployment-Guide

---

## ğŸš€ Quick Start

### Lokal testen

```bash

# Dependencies installieren

npm install

# Development-Server starten

npm run dev:remote

# Tool aufrufen

open http://127.0.0.1:8787/tools/webscraper/app

```bash

### API verwenden

```bash
# URL scrapen
curl -X POST http://127.0.0.1:8787/api/webscraper/extract \
  -H "Content-Type: application/json" \
  -H "X-CSRF-Token: YOUR_TOKEN" \
  -d '{"url": "https://example.com"}'
```

---

## ğŸ— Architektur

```text
Webscraper Tool
â”œâ”€â”€ Backend
â”‚   â”œâ”€â”€ Config (src/config/webscraper.ts)
â”‚   â”œâ”€â”€ Types (src/types/webscraper.ts)
â”‚   â”œâ”€â”€ Service (src/lib/services/webscraper-service.ts)
â”‚   â””â”€â”€ API (src/pages/api/webscraper/extract.ts)
â”œâ”€â”€ Frontend
â”‚   â”œâ”€â”€ Island (src/components/tools/webscraper/WebscraperIsland.tsx)
â”‚   â”œâ”€â”€ Form (src/components/tools/webscraper/WebscraperForm.tsx)
â”‚   â”œâ”€â”€ Results (src/components/tools/webscraper/WebscraperResults.tsx)
â”‚   â””â”€â”€ Pages (src/pages/{de,en,}/tools/webscraper/app.astro)
â”œâ”€â”€ Infrastructure
â”‚   â”œâ”€â”€ Migration (migrations/0022_create_scraping_jobs_table.sql)
â”‚   â””â”€â”€ KV (wrangler.toml)
â””â”€â”€ Tests
    â”œâ”€â”€ Unit (tests/unit/services/webscraper-service.test.ts)
    â”œâ”€â”€ Integration (tests/integration/api/webscraper.test.ts)
    â””â”€â”€ E2E (test-suite-v2/tests/webscraper.spec.ts)

```text

---

## ğŸ“Š Status

| Component         | Status      | Coverage |
| ----------------- | ----------- | -------- |
| Backend Service   | âœ… Complete | 100%     |
| API Endpoint      | âœ… Complete | 100%     |
| Frontend UI       | âœ… Complete | 100%     |
| Unit Tests        | âœ… Passing  | 10/10    |
| Integration Tests | âœ… Passing  | 7/7      |
| E2E Tests         | âœ… Passing  | 7/7      |
| Build             | âœ… Success  | 12.89 kB |

---

## ğŸ”§ Konfiguration

### Environment Variables

```bash
# Feature-Flag (default: true)
PUBLIC_WEBSCRAPER_V1=true

# Quotas
WEBSCRAPER_GUEST_LIMIT=5    # Requests/Tag fÃ¼r GÃ¤ste
WEBSCRAPER_USER_LIMIT=20    # Requests/Tag fÃ¼r eingeloggte User

# Timeouts
WEBSCRAPER_TIMEOUT=10000    # Fetch-Timeout in ms

# Limits
WEBSCRAPER_MAX_SIZE=5242880 # Max Response-GrÃ¶ÃŸe (5MB)

### Quota & Usage

Die effektiven Quoten werden planbasiert in `src/config/webscraper/entitlements.ts` gepflegt (`dailyBurstCap` pro rolling 24h Fenster, `monthlyRuns` pro Monat) und Ã¼ber `GET /api/webscraper/usage` exponiert. Die dort zurÃ¼ckgegebenen Felder `usage`/`dailyUsage` und â€“ sofern `KV_WEBSCRAPER` aktiv ist â€“ `monthlyUsage` sind maÃŸgeblich fÃ¼r UI/HUDs.

Die Environment-Variablen `WEBSCRAPER_GUEST_LIMIT` und `WEBSCRAPER_USER_LIMIT` speisen das `limits`-Objekt in der Usage-Response und dienen primÃ¤r als statische Defaults/Debug-Hilfen; die Durchsetzung von Limits erfolgt Ã¼ber die Entitlements (`dailyBurstCap`, `monthlyRuns`) und das 24h-/Monats-Usage-Tracking.

### KV-Namespaces

```toml

# Development

[[env.development.kv_namespaces]]
binding = "KV_WEBSCRAPER"
id = "webscraper-dev-local"

# Production

[[kv_namespaces]]
binding = "KV_WEBSCRAPER"
id = "webscraper-production"

```text

---

## ğŸ“– API-Referenz

### POST /api/webscraper/extract

**Request:**

```json
{
  "url": "https://example.com"
}
```

**Response (Success):**

```json
{
  "success": true,
  "data": {
    "result": {
      "url": "https://example.com",
      "title": "Example Domain",
      "description": "Example description",
      "text": "Page content...",
      "metadata": { "author": "...", "language": "en" },
      "links": ["https://example.com/page1"],
      "images": ["https://example.com/logo.png"],
      "scrapedAt": "2025-10-03T09:00:00.000Z",
      "robotsTxtAllowed": true
    },
    "usage": {
      "used": 1,
      "limit": 5,
      "resetAt": 1728037200000
    }
  }
}

```text

**Response (Error):**

```json
{
  "success": false,
  "error": {
    "type": "validation_error|forbidden|server_error",
    "message": "Error description"
  }
}
```

---

## ğŸ§ª Testing

```bash

# Unit-Tests

npm run test:unit:run -- tests/unit/services/webscraper-service.test.ts

# Integration-Tests

npm run test:integration:run -- tests/integration/api/webscraper.test.ts

# E2E-Tests (benÃ¶tigt laufenden Server)

npm run test:e2e -- webscraper.spec.ts

```text

---

## ğŸ› Bekannte Limitierungen (MVP)

1. **Kein JavaScript-Rendering** - Nur statisches HTML
1. **Kein Batch-Processing** - Eine URL pro Request
1. **Keine KI-Analyse** - Keine Sentiment/Entity-Erkennung
1. **Kein Monitoring** - Keine geplanten Scraping-Jobs
1. **Keine Bild-Downloads** - Nur URLs, keine Speicherung

â†’ Siehe [Roadmap](roadmap.md) fÃ¼r geplante Features in Phase 2-4

---

## ğŸ“ Best Practices

### FÃ¼r Entwickler

1. **robots.txt respektieren** - Das Tool lehnt automatisch blockierte URLs ab
1. **Quotas beachten** - GÃ¤ste: 5/Tag, User: 20/Tag
1. **Error-Handling** - Nutze strukturierte Fehler-Typen
1. **Testing** - Alle neuen Features mÃ¼ssen getestet sein (â‰¥70% Coverage)

### FÃ¼r Nutzer

1. **Verantwortungsvoller Einsatz** - Keine exzessiven Requests
1. **Rechtliche Compliance** - Urheberrecht und Datenschutz beachten
1. **robots.txt** - Wenn blockiert, respektiere die Entscheidung
1. **Quota-Management** - Bei Limit-Ãœberschreitung warten bis Reset

---

## ğŸ“ Support

- **Issues**: GitHub Issues im Evolution Hub Repository

- **Dokumentation**: Siehe [docs/tools/webscraper/](.)

- **Tests**: Siehe [tests/](../../../tests/)

---

**Version**: 1.0.0-mvp
**Last Updated**: 2025-10-27
**Status**: Production Ready âœ…

---

## ğŸ¯ Ãœberblick (2)

Das Webscraper-Tool ermÃ¶glicht es Nutzern, strukturierte Inhalte von Webseiten automatisch zu extrahieren. Es respektiert robots.txt-Regeln, implementiert Quota-Limits und bietet eine benutzerfreundliche UI.

### Hauptfeatures (2) (2)

- âœ… **URL-basierte Extraktion**: Titel, Meta-Daten, Text, Links, Bilder

- âœ… **robots.txt Compliance**: Automatische PrÃ¼fung und Einhaltung

- âœ… **Quota-System**: 5 Requests/Tag (Gast), 20 Requests/Tag (User)

- âœ… **Sicherheit**: Rate-Limiting, CSRF-Schutz, Input-Validierung

- âœ… **Internationalisierung**: Deutsch/Englisch

- âœ… **Responsive UI**: Mobile-First Design mit Tailwind CSS

---

## ğŸ“‹ Dokumentation (2)

- **[Specification](spec.md)** - Detaillierte Feature-Spezifikation

- **[Roadmap](roadmap.md)** - 14-Wochen Entwicklungsplan (Phasen 1-4)

- **[Guidelines](guidelines.md)** - Entwicklungsrichtlinien fÃ¼r Claude Code

- **[Testing Strategy](testing.md)** - Test-Pyramide und Quality-Metriken

- **[Implementation Complete](IMPLEMENTATION_COMPLETE.md)** - MVP-Status & Deployment-Guide

---

## ğŸš€ Quick Start (2)

### Lokal testen (2)

```bash
# Dependencies installieren
npm install

# Development-Server starten
npm run dev:remote

# Tool aufrufen
open http://127.0.0.1:8787/tools/webscraper/app
```

### API verwenden (2)

```bash

# URL scrapen

curl -X POST http://127.0.0.1:8787/api/webscraper/extract \
  -H "Content-Type: application/json" \
  -H "X-CSRF-Token: YOUR_TOKEN" \
  -d '{"url": "https://example.com"}'

```text

---

## ğŸ— Architektur (2)

```text
Webscraper Tool
â”œâ”€â”€ Backend
â”‚   â”œâ”€â”€ Config (src/config/webscraper.ts)
â”‚   â”œâ”€â”€ Types (src/types/webscraper.ts)
â”‚   â”œâ”€â”€ Service (src/lib/services/webscraper-service.ts)
â”‚   â””â”€â”€ API (src/pages/api/webscraper/extract.ts)
â”œâ”€â”€ Frontend
â”‚   â”œâ”€â”€ Island (src/components/tools/webscraper/WebscraperIsland.tsx)
â”‚   â”œâ”€â”€ Form (src/components/tools/webscraper/WebscraperForm.tsx)
â”‚   â”œâ”€â”€ Results (src/components/tools/webscraper/WebscraperResults.tsx)
â”‚   â””â”€â”€ Pages (src/pages/{de,en,}/tools/webscraper/app.astro)
â”œâ”€â”€ Infrastructure
â”‚   â”œâ”€â”€ Migration (migrations/0022_create_scraping_jobs_table.sql)
â”‚   â””â”€â”€ KV (wrangler.toml)
â””â”€â”€ Tests
    â”œâ”€â”€ Unit (tests/unit/services/webscraper-service.test.ts)
    â”œâ”€â”€ Integration (tests/integration/api/webscraper.test.ts)
    â””â”€â”€ E2E (test-suite-v2/tests/webscraper.spec.ts)
```

---

## ğŸ“Š Status (2)

| Component         | Status      | Coverage |
| ----------------- | ----------- | -------- |
| Backend Service   | âœ… Complete | 100%     |
| API Endpoint      | âœ… Complete | 100%     |
| Frontend UI       | âœ… Complete | 100%     |
| Unit Tests        | âœ… Passing  | 10/10    |
| Integration Tests | âœ… Passing  | 7/7      |
| E2E Tests         | âœ… Passing  | 7/7      |
| Build             | âœ… Success  | 12.89 kB |

---

## ğŸ”§ Konfiguration (2)

### Environment Variables (2)

```bash

# Feature-Flag (default: true)

PUBLIC_WEBSCRAPER_V1=true

# Quotas

WEBSCRAPER_GUEST_LIMIT=5    # Requests/Tag fÃ¼r GÃ¤ste
WEBSCRAPER_USER_LIMIT=20    # Requests/Tag fÃ¼r eingeloggte User

# Timeouts

WEBSCRAPER_TIMEOUT=10000    # Fetch-Timeout in ms

# Limits

WEBSCRAPER_MAX_SIZE=5242880 # Max Response-GrÃ¶ÃŸe (5MB)

```text

### KV-Namespaces (2)

```toml
# Development
[[env.development.kv_namespaces]]
binding = "KV_WEBSCRAPER"
id = "webscraper-dev-local"

# Production
[[kv_namespaces]]
binding = "KV_WEBSCRAPER"
id = "webscraper-production"
```

---

## ğŸ“– API-Referenz (2)

### POST /api/webscraper/extract (2)

**Request:**

```json
{
  "url": "https://example.com"
}

```json

**Response (Success):**

```json
{
  "success": true,
  "data": {
    "result": {
      "url": "https://example.com",
      "title": "Example Domain",
      "description": "Example description",
      "text": "Page content...",
      "metadata": { "author": "...", "language": "en" },
      "links": ["https://example.com/page1"],
      "images": ["https://example.com/logo.png"],
      "scrapedAt": "2025-10-03T09:00:00.000Z",
      "robotsTxtAllowed": true
    },
    "usage": {
      "used": 1,
      "limit": 5,
      "resetAt": 1728037200000
    }
  }
}
```

**Response (Error):**

```json
{
  "success": false,
  "error": {
    "type": "validation_error|forbidden|server_error",
    "message": "Error description"
  }
}

```bash

---

## ğŸ§ª Testing (2)

```bash
# Unit-Tests
npm run test:unit:run -- tests/unit/services/webscraper-service.test.ts

# Integration-Tests
npm run test:integration:run -- tests/integration/api/webscraper.test.ts

# E2E-Tests (benÃ¶tigt laufenden Server)
npm run test:e2e -- webscraper.spec.ts
```

---

## ğŸ› Bekannte Limitierungen (MVP) (2)

1. **Kein JavaScript-Rendering** - Nur statisches HTML
1. **Kein Batch-Processing** - Eine URL pro Request
1. **Keine KI-Analyse** - Keine Sentiment/Entity-Erkennung
1. **Kein Monitoring** - Keine geplanten Scraping-Jobs
1. **Keine Bild-Downloads** - Nur URLs, keine Speicherung

â†’ Siehe [Roadmap](roadmap.md) fÃ¼r geplante Features in Phase 2-4

---

## ğŸ“ Best Practices (2)

### FÃ¼r Entwickler (2)

1. **robots.txt respektieren** - Das Tool lehnt automatisch blockierte URLs ab
1. **Quotas beachten** - GÃ¤ste: 5/Tag, User: 20/Tag
1. **Error-Handling** - Nutze strukturierte Fehler-Typen
1. **Testing** - Alle neuen Features mÃ¼ssen getestet sein (â‰¥70% Coverage)

### FÃ¼r Nutzer (2)

1. **Verantwortungsvoller Einsatz** - Keine exzessiven Requests
1. **Rechtliche Compliance** - Urheberrecht und Datenschutz beachten
1. **robots.txt** - Wenn blockiert, respektiere die Entscheidung
1. **Quota-Management** - Bei Limit-Ãœberschreitung warten bis Reset

---

## ğŸ“ Support (2)

- **Issues**: GitHub Issues im Evolution Hub Repository

- **Dokumentation**: Siehe [docs/tools/webscraper/](.)

- **Tests**: Siehe [tests/](../../../tests/)

---

**Version**: 1.0.0-mvp
**Last Updated**: 2025-10-03
**Status**: Production Ready âœ…
