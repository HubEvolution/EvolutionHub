# Webscraper Tool - Spezifikation

## √úbersicht

Das Webscraper-Tool ist ein automatisiertes System zur intelligenten Extraktion, Verarbeitung und Strukturierung von Web-Inhalten. Es integriert sich nahtlos in die bestehende EvolutionHub-Tool-Palette und erweitert die M√∂glichkeiten durch externe Datenquellen.

## Ziele

- **Intelligente Datensammlung**: Automatische Erkennung und Extraktion strukturierter und unstrukturierter Daten
- **KI-gest√ºtzte Verarbeitung**: Verwendung von Machine Learning zur Content-Analyse und -aufbereitung
- **Nahtlose Integration**: Kompatibilit√§t mit bestehenden Tools (Image Enhancer, Prompt Enhancer)
- **Compliance & Ethik**: Respektierung rechtlicher Rahmenbedingungen und Web-Standards

## Kernfunktionen

### 1. URL-basierte Extraktion

**Eingabe-Interface**
- Einzelne URL oder Batch-Verarbeitung
- Unterst√ºtzung verschiedener Content-Types (Artikel, Produktseiten, Foren, etc.)
- Konfigurierbare Tiefen f√ºr Multi-Page-Sites

**Extraktions-Engine**
- DOM-parsing mit struktureller Analyse
- JavaScript-Rendering f√ºr dynamische Inhalte
- Intelligente Content-Erkennung (Titel, Text, Metadaten)

### 2. KI-gest√ºtzte Verarbeitung

**Content-Analyse**
- Automatische Zusammenfassung langer Artikel
- Sentiment-Analyse und Stimmungsbestimmung
- Entit√§ten-Erkennung (Personen, Organisationen, Orte)
- Thematische Kategorisierung

**Datenaufbereitung**
- Automatische Bereinigung von HTML-Artefakten
- Duplikaterkennung und -entfernung
- Strukturierte Datenausgabe (JSON, CSV, Markdown)

### 3. Monitoring & Alerts

**√Ñnderungs√ºberwachung**
- Regelm√§√üige √úberpr√ºfung von Webseiten
- Erkennung von Content-Updates
- Konfigurierbare Benachrichtigungen

**Preis-Monitoring**
- E-Commerce-Preisverfolgung
- Alert-System bei Preis√§nderungen
- Historische Preisanalyse

## Technische Architektur

### System-Komponenten

```mermaid
graph TB
    A[Frontend UI] --> B[API Routes]
    B --> C[Scraping Engine]
    C --> D[Content Parser]
    D --> E[AI Processor]
    E --> F[Data Storage]
    F --> G[Export Module]

    C --> H[Browser Engine]
    H --> I[Proxy Manager]
    I --> J[Rate Limiter]

    E --> K[ML Models]
    K --> L[Content Analyzer]
    L --> M[Entity Extractor]
```

### Technologie-Stack

**Frontend**
- Astro Island f√ºr UI-Komponente
- React/TypeScript f√ºr interaktive Elemente
- Tailwind CSS f√ºr konsistentes Design

**Backend**
- Cloudflare Workers f√ºr verteilte Verarbeitung
- Hono.js f√ºr API-Routen
- Drizzle ORM f√ºr Datenpersistierung

**Scraping-Engine**
- Puppeteer f√ºr Headless-Browser-Funktionalit√§t
- Cheerio f√ºr DOM-Parsing
- Custom Parser f√ºr strukturierte Daten

**AI-Komponenten**
- OpenAI GPT f√ºr Textverarbeitung
- Custom Models f√ºr Entit√§ten-Erkennung
- TensorFlow.js f√ºr client-seitige Analyse

## API-Design

### Endpunkte

```typescript
// Hauptextraktion
POST /api/webscraper/extract
{
  "url": "string",
  "options": {
    "depth": "number",
    "includeImages": "boolean",
    "summarize": "boolean"
  }
}

// Batch-Verarbeitung
POST /api/webscraper/batch
{
  "urls": ["string"],
  "config": "ScrapingConfig"
}

// Monitoring einrichten
POST /api/webscraper/monitor
{
  "url": "string",
  "frequency": "cron",
  "alerts": "AlertConfig"
}
```

### Datenmodelle

```typescript
interface ScrapingJob {
  id: string;
  url: string;
  status: 'pending' | 'running' | 'completed' | 'failed';
  createdAt: Date;
  completedAt?: Date;
  result?: ScrapingResult;
}

interface ScrapingResult {
  url: string;
  title: string;
  content: string;
  metadata: {
    author?: string;
    publishDate?: Date;
    tags?: string[];
    sentiment?: 'positive' | 'negative' | 'neutral';
  };
  entities: {
    persons: string[];
    organizations: string[];
    locations: string[];
  };
  images?: ImageData[];
  links: string[];
}
```

## UI/UX-Design

### Hauptinterface

**Dashboard-Layout**
- URL-Eingabefeld mit Validierung
- Konfigurationspanel (akkordeon-artig)
- Live-Preview w√§hrend der Extraktion
- Ergebnis-Darstellung mit Export-Optionen

**Ergebnisseite**
- Strukturierte Darstellung der extrahierten Daten
- Interaktive Entit√§ten-Hervorhebung
- Export-Interface f√ºr verschiedene Formate
- Visualisierung von Sentiment und Themen

### Responsive Design

- Mobile-first Ansatz
- Tablet-Optimierung f√ºr Recherche-Workflows
- Desktop-Erweiterungen f√ºr Power-User

## Sicherheitsaspekte

### Compliance

**Robots.txt-Respektierung**
- Automatische Erkennung und Einhaltung
- User-Override mit Warnhinweisen
- Logging von Compliance-Verst√∂√üen

**Rate Limiting**
- Adaptive Verz√∂gerungen basierend auf robots.txt
- User-Agent-Rotation
- Automatische Backoff-Strategie

**Content-Filter**
- Erkennung von sensiblen Inhalten
- PII-Detektion und -maskierung
- Rechtliche Content-Pr√ºfung

### Datenschutz

**Minimale Datenpersistierung**
- Tempor√§re Speicherung w√§hrend Verarbeitung
- Automatische Bereinigung nach Export
- Opt-in f√ºr Langzeitspeicherung

## Integration mit bestehenden Tools

### Synergien

**Image Enhancer Integration**
- Automatische Bildextraktion von Webseiten
- Batch-Verarbeitung f√ºr Bildergalerien
- Metadaten-Transfer zwischen Tools

**Prompt Enhancer Integration**
- Web-Content als Prompt-Eingabe
- Extrahierte Entit√§ten f√ºr Prompt-Anreicherung
- Cross-Tool-Content-Pipeline

**Content Generator Integration**
- Research-Material aus dem Web
- Automatische Quellen-Zitation
- Content-Validierung gegen Originale

## Testing-Strategie

### Unit-Tests

**Parser-Tests**
- Verschiedene HTML-Strukturen
- Edge-Cases und Fehlerbehandlung
- Performance-Tests f√ºr gro√üe Dokumente

**AI-Komponenten-Tests**
- Sentiment-Analyse-Genauigkeit
- Entit√§ten-Erkennung-Qualit√§t
- Zusammenfassungs-Qualit√§tsmetriken

### Integration-Tests

**End-to-End-Scraping**
- Komplette Website-Extraktion
- Multi-Page-Navigation
- JavaScript-lastige Anwendungen

**Cross-Tool-Integration**
- Datenfluss zwischen Tools
- Format-Kompatibilit√§t
- Fehlerpropagation-Tests

### E2E-Tests

**User-Workflows**
- Komplette Scraping-Sessions
- Export-Funktionalit√§ten
- Monitoring-Setup und -ausf√ºhrung

## Deployment & Infrastruktur

### Cloudflare-Integration

**Workers-Funktionen**
- Verteilte Scraping-Jobs
- Edge-nahe Verarbeitung
- Globale Proxy-Verteilung

**Storage-Strategie**
- D1 f√ºr Job-Metadaten
- R2 f√ºr tempor√§re Assets
- KV f√ºr Cache und Konfiguration

### Skalierungsaspekte

**Horizontale Skalierung**
- Worker-Instance-Management
- Load-Balancing f√ºr gro√üe Jobs
- Queue-System f√ºr Batch-Operationen

**Performance-Optimierung**
- Browser-Pooling
- Intelligente Caching-Strategie
- Kompression f√ºr gro√üe Datenmengen

## Erfolgsmetriken

### Technische KPIs

- **Extraktionsgenauigkeit**: >95% f√ºr strukturierte Daten
- **Verarbeitungsgeschwindigkeit**: <5s f√ºr durchschnittliche Seiten
- **Systemverf√ºgbarkeit**: >99.5% Uptime
- **Fehlerrate**: <1% bei Standard-Webseiten

### User-Experience-KPIs

- **Task-Completion-Rate**: >90% erfolgreiche Scraping-Operationen
- **User-Satisfaction-Score**: >4.5/5
- **Feature-Adoption**: >70% der aktiven User nutzen das Tool

## Detaillierte Entwicklungs-Roadmap

### **Phase 1: MVP-Grundlagen (Woche 1-4)**

#### **Woche 1: Setup & Foundation**
- Projektstruktur anlegen (`src/components/tools/webscraper/`, `src/lib/services/webscraper-service.ts`)
- Package.json Dependencies hinzuf√ºgen (`puppeteer`, `cheerio`, `@types/cheerio`)
- Grundlegende TypeScript-Interfaces definieren (`ScrapingJob`, `ScrapingResult`, `WebscraperConfig`)
- Basis-Konfiguration f√ºr Scraping-Engine erstellen

#### **Woche 2: Core Engine Development**
- Grundlegende Scraping-Engine implementieren (URL-Fetching, HTML-Parsing)
- Content-Extraktion entwickeln (Titel, Text, Metadaten, Links)
- Basis-Fehlerbehandlung und Logging integrieren
- Rate-Limiting nach Projektstandards implementieren

#### **Woche 3: API & Backend**
- API-Endpunkt `POST /api/webscraper/extract` implementieren
- Hono.js Route mit Validierung und Fehlerbehandlung
- Datenbank-Schema f√ºr Scraping-Jobs (D1-Migration)
- Grundlegende Authentifizierung und CSRF-Schutz

#### **Woche 4: Frontend & UI**
- Astro-Island-Komponente `WebscraperIsland.tsx` erstellen
- Einfaches URL-Eingabeformular mit Validierung
- Ergebnis-Display-Komponente entwickeln
- Responsive Design nach Projektstandards

### **Phase 2: Kernfunktionen (Woche 5-10)**

#### **Woche 5-6: KI-Integration**
- OpenAI GPT-Integration f√ºr Textverarbeitung
- Sentiment-Analyse implementieren
- Entit√§ten-Erkennung entwickeln (NER)
- Automatische Zusammenfassung von Artikeln

#### **Woche 7-8: Erweiterte Features**
- Batch-Verarbeitung f√ºr mehrere URLs
- Export-Funktionalit√§ten (JSON, CSV, Markdown)
- Bild-Extraktion und -verarbeitung
- Monitoring-System-Grundlagen

#### **Woche 9-10: Advanced Features**
- JavaScript-Rendering f√ºr dynamische Inhalte
- Intelligente Content-Filter und -bereinigung
- Cache-System f√ºr wiederholte Anfragen
- Performance-Optimierung und Browser-Pooling

### **Phase 3: Integration & Testing (Woche 11-12)**

#### **Woche 11: Cross-Tool-Integration**
- Integration mit Image Enhancer testen
- Integration mit Prompt Enhancer entwickeln
- Datenfluss zwischen Tools validieren
- Cross-Tool-API-Endpunkte implementieren

#### **Woche 12: Testing & Quality**
- Umfassende Unit-Test-Suite entwickeln
- Integration-Tests f√ºr alle Features
- E2E-Tests mit Playwright implementieren
- Sicherheitsaudit und Penetration-Testing

### **Phase 4: Deployment & Launch (Woche 13-14)**

#### **Woche 13: Production-Setup**
- Cloudflare Workers-Konfiguration optimieren
- Datenbank-Migrationen durchf√ºhren
- Monitoring und Logging einrichten (Sentry, Analytics)
- Load-Testing und Performance-Validierung

#### **Woche 14: Launch-Vorbereitung**
- Dokumentation finalisieren (User-Guides, API-Docs)
- Beta-Testing mit ausgew√§hlten Usern
- Security-Review und Compliance-Check
- Launch-Planung und Marketing-Materialien

## Milestones & Deliverables

### **MVP-Milestone (Ende Woche 4)**
- ‚úÖ Einzelne URL-Extraktion funktioniert
- ‚úÖ Grundlegende UI ist benutzbar
- ‚úÖ API-Endpunkt ist verf√ºgbar
- ‚úÖ Basis-Testing ist implementiert

### **Feature-Complete-Milestone (Ende Woche 10)**
- ‚úÖ Alle Kernfunktionen sind implementiert
- ‚úÖ KI-Integration ist funktionsf√§hig
- ‚úÖ Export-Funktionen arbeiten korrekt
- ‚úÖ Performance-Ziele sind erreicht

### **Production-Ready-Milestone (Ende Woche 12)**
- ‚úÖ Vollst√§ndige Test-Coverage erreicht
- ‚úÖ Sicherheitsaudit bestanden
- ‚úÖ Cross-Tool-Integration getestet
- ‚úÖ Dokumentation ist vollst√§ndig

### **Launch-Milestone (Ende Woche 14)**
- ‚úÖ Produktionsumgebung ist stabil
- ‚úÖ Monitoring ist eingerichtet
- ‚úÖ Beta-Testing erfolgreich abgeschlossen
- ‚úÖ Launch-Kriterien erf√ºllt

## Risiken & Mitigation

### Technische Risiken

**Anti-Scraping-Mechanismen**
- Mitigation: Adaptive Browser-Fingerprints
- Fallback: Alternative Extraktionsmethoden

**JavaScript-lastige Seiten**
- Mitigation: Vollst√§ndiges Browser-Rendering
- Fallback: Hybride Parsing-Ans√§tze

### Rechtliche Risiken

**Copyright-Inhalte**
- Mitigation: Faire-Nutzung-Pr√ºfung
- User-Education: Richtlinien und Warnhinweise

**Datenschutz**
- Mitigation: PII-Detektion und -entfernung
- Compliance: GDPR-konforme Verarbeitung

## Budget & Ressourcen

### Entwicklung

- **Entwicklungszeit**: 14 Wochen
- **Team-Gr√∂√üe**: 2-3 Entwickler
- **QA-Ressourcen**: 1 Tester f√ºr E2E-Tests

### Infrastruktur

- **Cloudflare-Kosten**: Workers + Storage
- **AI-API-Kosten**: OpenAI/Together AI
- **Monitoring-Tools**: Sentry, Analytics

## Akzeptanzkriterien

### Funktionale Kriterien

- [ ] Einzelne URL-Extraktion funktioniert zuverl√§ssig
- [ ] Batch-Verarbeitung f√ºr bis zu 10 URLs
- [ ] Export in mindestens 3 Formaten
- [ ] Grundlegende Sentiment-Analyse
- [ ] Integration mit einem bestehenden Tool

### Nicht-funktionale Kriterien

- [ ] Performance: <3s f√ºr durchschnittliche Seiten
- [ ] Sicherheit: Bestanden Security-Audit
- [ ] Accessibility: WCAG 2.1 AA-konform
- [ ] Mobile: Vollst√§ndig responsive
- [ ] Testing: >80% Test-Coverage

## Support & Dokumentation

### User-Dokumentation

- **In-App-Hilfe**: Kontextsensitive Tooltips
- **Video-Tutorials**: Screencasts f√ºr komplexe Workflows
- **Knowledge-Base**: Umfassende Anleitungen
- **API-Dokumentation**: OpenAPI-Spezifikation

### Technische Dokumentation

- **Architektur-Dokumente**: System-Design und -fl√ºsse
- **Deployment-Guides**: Setup und Konfiguration
- **Troubleshooting**: H√§ufige Probleme und L√∂sungen
- **API-Referenz**: Vollst√§ndige Endpunkt-Dokumentation

## Claude Code Entwicklungs-Guidelines

### **üöÄ Entwicklungshinweise f√ºr Claude Code**

**Diese Spezifikation dient als prim√§re Entwicklungsgrundlage. Bitte beachten Sie:**

#### **Entwicklungsansatz**
- **Iterative Entwicklung**: Beginnen Sie mit Woche 1 und arbeiten Sie sich vor
- **Test-Driven Development**: Schreiben Sie Tests vor der Implementierung
- **Security-First**: Ber√ºcksichtigen Sie Sicherheitsaspekte von Anfang an
- **Performance-Conscious**: Optimieren Sie f√ºr Cloudflare Workers Edge Runtime

#### **Code-Strukturierung**
```typescript
// Bevorzugte Projektstruktur:
src/
‚îú‚îÄ‚îÄ components/tools/webscraper/
‚îÇ   ‚îú‚îÄ‚îÄ WebscraperIsland.tsx          // Haupt-UI-Komponente
‚îÇ   ‚îú‚îÄ‚îÄ WebscraperForm.tsx            // Eingabeformular
‚îÇ   ‚îú‚îÄ‚îÄ WebscraperResults.tsx         // Ergebnis-Display
‚îÇ   ‚îî‚îÄ‚îÄ types.ts                      // Lokale TypeScript-Interfaces
‚îú‚îÄ‚îÄ lib/services/
‚îÇ   ‚îî‚îÄ‚îÄ webscraper-service.ts         // Kernlogik und API-Calls
‚îú‚îÄ‚îÄ pages/api/webscraper/
‚îÇ   ‚îú‚îÄ‚îÄ extract.ts                    // Haupt-API-Endpunkt
‚îÇ   ‚îî‚îÄ‚îÄ [..slugs].ts                  // Catch-all f√ºr zuk√ºnftige Endpunkte
‚îî‚îÄ‚îÄ config/
    ‚îî‚îÄ‚îÄ webscraper.ts                 // Konfiguration und Constants
```

#### **Coding Standards ( strikt befolgen)**

**TypeScript-Richtlinien**
- **Strict Mode**: Immer `strict: true` in tsconfig.json
- **Keine `any` Types**: Verwenden Sie spezifische Interface-Definitionen
- **Error Handling**: Umfassende Fehlerbehandlung mit strukturierten Fehlern
- **Async/Await**: Konsequente Verwendung f√ºr alle asynchronen Operationen

**API-Entwicklung**
- **Hono.js Framework**: Verwenden Sie die bestehenden Muster aus dem Projekt
- **Request Validation**: Valideren Sie alle Eingaben mit Zod oder √§hnlichen Tools
- **Response Format**: Konsistentes `{ success: true, data: T }` Format
- **Error Responses**: Strukturierte Fehler mit `{ success: false, error: {...} }`

**Sicherheitsanforderungen**
- **CSRF Protection**: Implementieren Sie Double-Submit-Cookie-Muster
- **Rate Limiting**: Begrenzen Sie Anfragen nach Projektstandards
- **Input Sanitization**: Bereinigen Sie alle Benutzereingaben
- **HTTPS Only**: Erzwingen Sie sichere Verbindungen

#### **Testing-Anforderungen**

**Unit-Tests**
```typescript
// Beispiel-Teststruktur
describe('WebscraperService', () => {
  it('should extract content from valid URL', async () => {
    const result = await webscraperService.extract('https://example.com');
    expect(result.success).toBe(true);
    expect(result.data.title).toBeDefined();
  });
});
```

**Integration-Tests**
- Testen Sie die kompletten API-Endpunkte
- Validieren Sie Datenbank-Interaktionen
- Testen Sie Fehlerf√§lle und Edge-Cases

**E2E-Tests**
- Verwenden Sie Playwright f√ºr Browser-Interaktionen
- Testen Sie komplette User-Workflows
- Integrieren Sie visuelle Regression-Tests

#### **Performance-Optimierung**

**Cloudflare Workers Optimierung**
- **Bundle Size**: Halten Sie Bundles unter 1MB
- **Cold Starts**: Minimieren Sie Initialisierungszeit
- **Memory Usage**: Effiziente Speicherverwaltung
- **Network Requests**: Optimieren Sie externe API-Calls

**Browser-Performance**
- **Lazy Loading**: Implementieren Sie f√ºr schwere Komponenten
- **Caching**: Nutzen Sie Service Worker f√ºr Offline-F√§higkeiten
- **Image Optimization**: Komprimieren Sie automatisch Bilder

#### **Monitoring & Observability**

**Logging-Standards**
```typescript
// Strukturiertes Logging nach Projektstandards
logger.info('Scraping job started', {
  jobId: '123',
  url: 'https://example.com',
  userId: 'user_456'
});
```

**Fehlerbehandlung**
- **Graceful Degradation**: Fallbacks f√ºr fehlgeschlagene Operationen
- **User-Friendly Messages**: Klare Fehlermeldungen f√ºr Endbenutzer
- **Debugging Support**: Detaillierte Logs f√ºr Entwickler

#### **Deployment & DevOps**

**Umgebungsmanagement**
- **Environment Variables**: Verwenden Sie Wrangler Secrets
- **Feature Flags**: Implementieren Sie f√ºr neue Features
- **Staged Rollouts**: Graduelle Einf√ºhrung neuer Versionen

**CI/CD-Integration**
- **Automated Testing**: Alle Tests m√ºssen in CI bestehen
- **Linting**: ESLint und Prettier m√ºssen sauber sein
- **Security Scans**: Automatische Sicherheitspr√ºfungen

### **üìã Checklisten f√ºr jeden Entwicklungsschritt**

#### **Vor der Implementierung**
- [ ] **Anforderungsanalyse**: Verstehen Sie die Spezifikation vollst√§ndig
- [ ] **Architektur-Planung**: Entwerfen Sie die L√∂sungsarchitektur
- [ ] **Test-Planung**: Definieren Sie Testf√§lle im Voraus
- [ ] **Sicherheitsbewertung**: Identifizieren Sie potenzielle Risiken

#### **W√§hrend der Implementierung**
- [ ] **Code-Standards**: Befolgen Sie die Projekt-Coding-Standards
- [ ] **Error Handling**: Implementieren Sie umfassende Fehlerbehandlung
- [ ] **Logging**: F√ºgen Sie strukturiertes Logging hinzu
- [ ] **Dokumentation**: Kommentieren Sie komplexe Logik

#### **Vor dem Commit**
- [ ] **Tests**: Alle Tests m√ºssen bestehen
- [ ] **Linting**: Code muss ESLint/Prettier-konform sein
- [ ] **Type Checking**: TypeScript-Fehler m√ºssen behoben sein
- [ ] **Security Review**: Pr√ºfen Sie auf Sicherheitsl√ºcken

#### **Vor dem Deployment**
- [ ] **Integration-Tests**: Cross-Tool-Interaktionen testen
- [ ] **Performance-Tests**: Last-Testing durchf√ºhren
- [ ] **Accessibility**: WCAG 2.1 AA-Compliance sicherstellen
- [ ] **Documentation**: Aktualisieren Sie Benutzerdokumentation

### **üîß N√ºtzliche Entwicklungstools**

#### **Lokale Entwicklung**
```bash
# Entwicklungsserver starten
npm run dev

# Tests ausf√ºhren
npm run test:unit
npm run test:e2e

# Type-Checking
npm run astro:check

# Linting
npm run lint
```

#### **Cloudflare Workers**
```bash
# Lokales Testing
npm run wrangler:dev

# Deployment
npm run deploy

# Logs anzeigen
npm run wrangler:tails
```

### **‚ö° Best Practices f√ºr KI-gest√ºtzte Entwicklung**

**Prompt Engineering**
- **Spezifische Anweisungen**: Seien Sie explizit in Ihren Anforderungen
- **Kontext-Bereitstellung**: Stellen Sie relevante Code-Beispiele zur Verf√ºgung
- **Iterative Verfeinerung**: Bauen Sie auf vorherigen Ergebnissen auf

**Code-Review**
- **Selbstkritik**: Hinterfragen Sie generierten Code kritisch
- **Sicherheitspr√ºfung**: √úberpr√ºfen Sie generierten Code auf Sicherheitsl√ºcken
- **Performance-Analyse**: Bewerten Sie die Effizienz des Codes

**Testing**
- **Edge-Case-Coverage**: Testen Sie ungew√∂hnliche Szenarien
- **Error-Scenario-Testing**: Validieren Sie Fehlerbehandlung
- **Performance-Testing**: Messen Sie Antwortzeiten und Ressourcenverbrauch

### **üö® Wichtige Warnhinweise**

#### **Sicherheitskritische Aspekte**
- **Keine Secrets im Code**: Verwenden Sie Environment Variables
- **Input Validation**: Validieren Sie alle Benutzereingaben streng
- **Rate Limiting**: Implementieren Sie Schutz vor Missbrauch
- **PII Handling**: Achten Sie auf personenbezogene Daten

#### **Performance-Kritische Aspekte**
- **Memory Leaks**: Vermeiden Sie Speicherlecks in Workers
- **Infinite Loops**: Sch√ºtzen Sie vor endlosen Schleifen
- **Resource Limits**: Respektieren Sie Cloudflare Workers Limits
- **Cold Start Optimization**: Minimieren Sie Initialisierungszeit

#### **Qualit√§tskritische Aspekte**
- **Code Duplication**: Vermeiden Sie wiederholten Code
- **Maintainability**: Schreiben Sie wartbaren und erweiterbaren Code
- **Documentation**: Dokumentieren Sie komplexe Logik
- **Standards Compliance**: Halten Sie sich an Projektstandards

---

## **üìû Support & Communication**

### **Bei Fragen oder Problemen**
1. **Dokumentation**: Konsultieren Sie zun√§chst diese Spezifikation
2. **Code-Beispiele**: Schauen Sie sich bestehende Tools an (Image Enhancer, Prompt Enhancer)
3. **Projektstandards**: Beachten Sie die GLOBAL_RULES.md und CLAUDE.md
4. **Team-Konsultation**: Fragen Sie bei Unklarheiten nach

### **Entwicklungsfortschritt**
- **Regelm√§√üige Updates**: Halten Sie die Todo-Liste aktuell
- **Milestone-Reporting**: Melden Sie erreichte Meilensteine
- **Problem-Eskalation**: Eskalieren Sie Blockierer fr√ºhzeitig

---

*üéØ Diese Spezifikation ist bereit f√ºr die √úbergabe an Claude Code und dient als umfassende Entwicklungsgrundlage f√ºr das Webscraper-Tool.*

**Erfolgreiche Entwicklung! üöÄ**